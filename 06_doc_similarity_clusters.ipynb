{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook to illustrate document similarity clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# following only used for development, reloads the modules with any code changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# inline matplotlib charts\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import our text mining toolkit\n",
    "import text_mining_toolkit as tmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_directory =  data_sets/hillsborough/txt/\n",
      "text_filename_pattern =  H*.txt\n",
      "self.documents populated =  4047\n"
     ]
    }
   ],
   "source": [
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/simple_test/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/recipes/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(directory_of_files=\"data_sets/mystery_corpus_01/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/iraq_inquiry/txt/\", text_filename_pattern=\"the-report*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/clinton_emails/txt/\", text_filename_pattern=\"C0*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/shakespeare_macbeth/txt/\", text_filename_pattern=\"macbeth_act_0?_scene_0?.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/mixed/txt/\", text_filename_pattern=\"*.txt\")\n",
    "cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/hillsborough/txt/\", text_filename_pattern=\"H*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed wordcount index file:  data_sets/hillsborough/txt/index_wordcount.hdf5\n"
     ]
    }
   ],
   "source": [
    "# first clear index\n",
    "tmt.index_wordcount.delete_index(cr.content_directory)\n",
    "\n",
    "# for all documents in corpus\n",
    "for document_name in cr.get_documents():\n",
    "    #print(\"processing \", document_name)\n",
    "\n",
    "    # get document text\n",
    "    document_text = cr.get_text_by_document(document_name)\n",
    "\n",
    "    # simplify whitespace (remove newlines)\n",
    "    b = tmt.text_processing.simplify_whitespace(document_text)\n",
    "\n",
    "    # only keep alphanumeric characters, removes punctuation\n",
    "    c = tmt.text_processing.keep_only_alphanumeric(b)\n",
    "\n",
    "    # make lowercase\n",
    "    d = tmt.text_processing.to_lowercase(c)\n",
    "\n",
    "    # split into words list\n",
    "    dl = tmt.text_processing.split_text_into_words(d)\n",
    "    \n",
    "    # build n-grams\n",
    "    #gl = tmt.word_processing.build_ngrams_from_words(dl,2)\n",
    "\n",
    "    # remove stop words\n",
    "    el = tmt.word_processing.remove_stop_words(dl, \"./stopwords/minimal-stop.txt\")\n",
    "\n",
    "    # only keep words with min length 5\n",
    "    fl = tmt.word_processing.keep_words_min_length(el,5)\n",
    "    \n",
    "    # update index\n",
    "    tmt.index_wordcount.create_wordcount_index_for_document(cr.content_directory, document_name, fl)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving corpus word count index ...  data_sets/hillsborough/txt/index_wordcount.hdf5\n"
     ]
    }
   ],
   "source": [
    "# merge document indices into a corpus index\n",
    "tmt.index_wordcount.merge_wordcount_indices_for_corpus(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed relevance index file:  data_sets/hillsborough/txt/index_relevance.hdf5\n",
      "saving corpus relevance index ...  data_sets/hillsborough/txt/index_relevance.hdf5\n"
     ]
    }
   ],
   "source": [
    "# delete and build relevance index\n",
    "\n",
    "tmt.index_relevance.delete_index(cr.content_directory)\n",
    "tmt.index_relevance.calculate_relevance_index(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate document similarities\n",
    "\n",
    "# delete if already exists\n",
    "tmt.index_doc_similarity.delete_matrix(cr.content_directory)\n",
    "\n",
    "# calclate doc1-doc2 similarity\n",
    "%time tmt.index_doc_similarity.create_doc_similarity_matrix(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_similarity_matrix_file  data_sets/simple_test/txt/matrix_docsimilarity.hdf5\n",
      "          02.txt    03.txt  04.txt  05.txt\n",
      "01.txt  0.160526  0.095418     0.0     0.0\n",
      "02.txt  0.000000  0.475525     0.0     0.0\n",
      "03.txt  0.000000  0.000000     0.0     0.0\n",
      "04.txt  0.000000  0.000000     0.0     0.0\n"
     ]
    }
   ],
   "source": [
    "tmt.index_doc_similarity.print_matrix(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 ms, sys: 1.39 ms, total: 12.5 ms\n",
      "Wall time: 13 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.txt</td>\n",
       "      <td>03.txt</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.txt</td>\n",
       "      <td>02.txt</td>\n",
       "      <td>0.337578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.txt</td>\n",
       "      <td>03.txt</td>\n",
       "      <td>0.200658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc1    doc2  similarity\n",
       "0  02.txt  03.txt    1.000000\n",
       "1  01.txt  02.txt    0.337578\n",
       "2  01.txt  03.txt    0.200658"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get document similarities order by value\n",
    "%time doc1_doc2_similarity = tmt.index_doc_similarity.get_doc_pairs_by_similarity(cr.content_directory)\n",
    "doc1_doc2_similarity[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"d3-container-4146863\"></div>\n",
       "<div>force-directed graph</div>\n",
       "\n",
       "<style>\n",
       "    .links line {\n",
       "        stroke: #999;\n",
       "        stroke-opacity: .1;\n",
       "    }\n",
       "\n",
       "    .nodes circle {\n",
       "        pointer-events: all;\n",
       "        stroke: #fff;\n",
       "        fill: #333;\n",
       "        stroke-width: 1.5px;\n",
       "        opacity: 0.7;\n",
       "    }\n",
       "\n",
       "    .nodes text {\n",
       "        pointer-events: none;\n",
       "        font: 10px sans-serif;\n",
       "        fill: #333;\n",
       "        opacity: .5;\n",
       "    }\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "// require is needed to make d3 work in jupyter notebooks from imported code\n",
       "require.config({\n",
       "    paths: {\n",
       "        d3: \"https://d3js.org/d3.v4.min\"\n",
       "    }\n",
       "});\n",
       "\n",
       "require([\"d3\"], function(d3) {\n",
       "    //console.log(d3.version);\n",
       "\n",
       "    var width = 800,\n",
       "        height = 600;\n",
       "\n",
       "    var svg = d3.select(\"#d3-container-4146863\")\n",
       "        .append(\"svg\")\n",
       "        .attr(\"width\", width)\n",
       "        .attr(\"height\", height);\n",
       "\n",
       "    var colour = d3.scaleOrdinal(d3.schemeCategory20c);\n",
       "\n",
       "    var graph = {\n",
       "        nodes: [{'id': '02.txt'}, {'id': '01.txt'}, {'id': '03.txt'}],\n",
       "        links: [{'similarity': 0.3375775159493023, 'source': 0, 'target': 1}, {'similarity': 1.0, 'source': 0, 'target': 2}, {'similarity': 0.2006580851240318, 'source': 1, 'target': 2}]\n",
       "    };\n",
       "\n",
       "    var simulation = d3.forceSimulation(graph.nodes)\n",
       "        .force(\"link\", d3.forceLink(graph.links).distance(function(d){return 10 / d.similarity;}))\n",
       "        .force(\"charge\", d3.forceManyBody().strength(-20))\n",
       "        .force(\"radius\", d3.forceCollide(15))\n",
       "        .force(\"center\", d3.forceCenter(width / 2.0, height / 2.0));\n",
       "\n",
       "    var link = svg.append(\"g\")\n",
       "        .attr(\"class\", \"links\")\n",
       "        .selectAll(\"line\")\n",
       "        .data(graph.links)\n",
       "        .enter().append(\"line\")\n",
       "        .style(\"stroke-linecap\", \"round\")\n",
       "        .style(\"stroke\", function(d) {return colour(d.similarity);})\n",
       "        .style(\"stroke-width\", function (d) {return Math.sqrt(d.similarity*10);});\n",
       "\n",
       "    var node = svg.append(\"g\")\n",
       "        .attr(\"class\", \"nodes\")\n",
       "        .selectAll(\"g\")\n",
       "        .data(graph.nodes)\n",
       "        .enter().append(\"g\");\n",
       "\n",
       "    var circle = node.append(\"circle\")\n",
       "        .attr(\"r\", 4.5)\n",
       "        .call(d3.drag()\n",
       "            .on(\"start\", dragstarted)\n",
       "            .on(\"drag\", dragged)\n",
       "            .on(\"end\", dragended));\n",
       "\n",
       "    //node.append(\"title\")\n",
       "    //    .text(function(d) { return d.id; });\n",
       "\n",
       "    var t2 = node.append(\"text\")\n",
       "      .attr(\"dx\", 10)\n",
       "      .attr(\"dy\", \".35em\")\n",
       "      .text(function(d) { return d.id; });\n",
       "\n",
       "    simulation\n",
       "        .on(\"tick\", ticked);\n",
       "\n",
       "    function ticked() {\n",
       "        link\n",
       "            .attr(\"x1\", function(d) { return d.source.x; })\n",
       "            .attr(\"y1\", function(d) { return d.source.y; })\n",
       "            .attr(\"x2\", function(d) { return d.target.x; })\n",
       "            .attr(\"y2\", function(d) { return d.target.y; });\n",
       "\n",
       "        circle\n",
       "            .attr(\"cx\", function(d) { return d.x; })\n",
       "            .attr(\"cy\", function(d) { return d.y; });\n",
       "\n",
       "        t2\n",
       "            .attr(\"x\", function(d) { return d.x; })\n",
       "            .attr(\"y\", function(d) { return d.y; });\n",
       "    };\n",
       "\n",
       "    function dragstarted(d) {\n",
       "        if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n",
       "        d.fx = d.x;\n",
       "        d.fy = d.y;\n",
       "    };\n",
       "\n",
       "    function dragged(d) {\n",
       "        d.fx = d3.event.x;\n",
       "        d.fy = d3.event.y;\n",
       "    };\n",
       "\n",
       "    function dragended(d) {\n",
       "        if (!d3.event.active) simulation.alphaTarget(0);\n",
       "        d.fx = null;\n",
       "        d.fy = null;\n",
       "    };\n",
       "\n",
       "});\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the doc similarities\n",
    "tmt.visualisation.plot_force_directed_graph(doc1_doc2_similarity[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "02.txt    0.166731\n",
       "03.txt    0.111154\n",
       "01.txt    0.047637\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query a word\n",
    "tmt.index_relevance.search_relevance_index(cr.content_directory, 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
