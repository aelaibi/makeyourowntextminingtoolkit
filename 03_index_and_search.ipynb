{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook to illustrate text indexing and basic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# following only used for development, reloads the modules with any code changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# inline matplotlib charts\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import our text mining toolkit\n",
    "import text_mining_toolkit as tmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_directory =  data_sets/simple_test/txt/\n",
      "text_filename_pattern =  ??.txt\n",
      "self.documents populated =  5\n"
     ]
    }
   ],
   "source": [
    "cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/simple_test/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/recipes/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(directory_of_files=\"data_sets/mystery_corpus_01/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/iraq_inquiry/txt/\", text_filename_pattern=\"the-report*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/clinton_emails/txt/\", text_filename_pattern=\"C0*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/shakespeare_macbeth/txt/\", text_filename_pattern=\"macbeth_act_0?_scene_0?.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed wordcount index file:  data_sets/simple_test/txt/index_wordcount.hdf5\n",
      "processing  01.txt\n",
      "processing  02.txt\n",
      "processing  03.txt\n",
      "processing  04.txt\n",
      "processing  05.txt\n"
     ]
    }
   ],
   "source": [
    "# first clear index\n",
    "tmt.index_wordcount.delete_index(cr.content_directory)\n",
    "\n",
    "# for all documents in corpus\n",
    "for document_name in cr.get_documents():\n",
    "    print(\"processing \", document_name)\n",
    "\n",
    "    # get document text\n",
    "    document_text = cr.get_text_by_document(document_name)\n",
    "\n",
    "    # simplify whitespace (remove newlines)\n",
    "    b = tmt.text_processing.simplify_whitespace(document_text)\n",
    "\n",
    "    # only keep alphanumeric characters, removes punctuation\n",
    "    c = tmt.text_processing.keep_only_alphanumeric(b)\n",
    "\n",
    "    # make lowercase\n",
    "    d = tmt.text_processing.to_lowercase(c)\n",
    "\n",
    "    # split into words list\n",
    "    dl = tmt.text_processing.split_text_into_words(d)\n",
    "    \n",
    "    # build n-grams\n",
    "    #gl = tmt.word_processing.build_ngrams_from_words(dl,2)\n",
    "\n",
    "    # remove stop words\n",
    "    #el = tmt.word_processing.remove_stop_words(dl, \"./stopwords/minimal-stop.txt\")\n",
    "    \n",
    "    # update index\n",
    "    tmt.index_wordcount.create_wordcount_index_for_document(cr.content_directory, document_name, dl)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving corpus word count index ...  data_sets/simple_test/txt/index_wordcount.hdf5\n"
     ]
    }
   ],
   "source": [
    "# merge document indices into a corpus index\n",
    "tmt.index_wordcount.merge_wordcount_indices_for_corpus(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordcount_index_file  data_sets/simple_test/txt/index_wordcount.hdf5\n",
      "        01.txt  02.txt  03.txt  04.txt  05.txt\n",
      "apple      3.0     0.0     0.0     0.0     0.0\n",
      "banana     0.0     1.0     0.0     0.0     0.0\n",
      "kiwi       0.0     0.0     1.0     0.0     0.0\n",
      "orange     1.0     4.0     1.0     0.0     0.0\n",
      "seats      0.0     0.0     0.0     0.0     1.0\n",
      "wheels     0.0     0.0     0.0     1.0     0.0\n"
     ]
    }
   ],
   "source": [
    "tmt.index_wordcount.print_index(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "02.txt    4.0\n",
       "03.txt    1.0\n",
       "01.txt    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmt.index_wordcount.search_wordcount_index(cr.content_directory, \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
