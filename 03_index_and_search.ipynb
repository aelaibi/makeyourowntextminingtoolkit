{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook to illustrate text indexing and basic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# following only used for development, reloads the modules with any code changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# inline matplotlib charts\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our text mining toolkit\n",
    "import text_mining_toolkit as tmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_directory =  data_sets/recipes/txt/\n",
      "text_filename_pattern =  ??.txt\n",
      "self.documents populated =  22\n"
     ]
    }
   ],
   "source": [
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/simple_test/txt/\", text_filename_pattern=\"??.txt\")\n",
    "cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/recipes/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(directory_of_files=\"data_sets/mystery_corpus_01/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/iraq_inquiry/txt/\", text_filename_pattern=\"the-report*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/clinton_emails/txt/\", text_filename_pattern=\"C0*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/shakespeare_macbeth/txt/\", text_filename_pattern=\"macbeth_act_0?_scene_0?.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  00.txt\n",
      "processing  01.txt\n",
      "processing  02.txt\n",
      "processing  03.txt\n",
      "processing  04.txt\n",
      "processing  05.txt\n",
      "processing  06.txt\n",
      "processing  07.txt\n",
      "processing  08.txt\n",
      "processing  09.txt\n",
      "processing  10.txt\n",
      "processing  11.txt\n",
      "processing  12.txt\n",
      "processing  13.txt\n",
      "processing  14.txt\n",
      "processing  15.txt\n",
      "processing  16.txt\n",
      "processing  17.txt\n",
      "processing  18.txt\n",
      "processing  19.txt\n",
      "processing  20.txt\n",
      "processing  21.txt\n"
     ]
    }
   ],
   "source": [
    "# first clear index\n",
    "tmt.index_wordcount.delete_index(cr.content_directory)\n",
    "\n",
    "# for all documents in corpus\n",
    "for document_name in cr.get_documents():\n",
    "    print(\"processing \", document_name)\n",
    "\n",
    "    # get document text\n",
    "    document_text = cr.get_text_by_document(document_name)\n",
    "\n",
    "    # simplify whitespace (remove newlines)\n",
    "    b = tmt.text_processing.simplify_whitespace(document_text)\n",
    "\n",
    "    # only keep alphanumeric characters, removes punctuation\n",
    "    c = tmt.text_processing.keep_only_alphanumeric(b)\n",
    "\n",
    "    # make lowercase\n",
    "    d = tmt.text_processing.to_lowercase(c)\n",
    "\n",
    "    # split into words list\n",
    "    dl = tmt.text_processing.split_text_into_words(d)\n",
    "    \n",
    "    # build n-grams\n",
    "    #gl = tmt.word_processing.build_ngrams_from_words(dl,2)\n",
    "\n",
    "    # remove stop words\n",
    "    #el = tmt.word_processing.remove_stop_words(dl, \"./stopwords/minimal-stop.txt\")\n",
    "    \n",
    "    # update index\n",
    "    tmt.index_wordcount.create_wordcount_index_for_document(cr.content_directory, document_name, dl)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving corpus word count index ...  data_sets/recipes/txt/index_wordcount.hdf5\n"
     ]
    }
   ],
   "source": [
    "# merge document indices into a corpus index\n",
    "tmt.index_wordcount.merge_wordcount_indices_for_corpus(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordcount_index_file  data_sets/recipes/txt/index_wordcount.hdf5\n",
      "       00.txt  01.txt   ...    20.txt  21.txt\n",
      "1         0.0     0.0   ...       0.0     0.0\n",
      "12        0.0     0.0   ...       0.0     1.0\n",
      "14        0.0     0.0   ...       0.0     0.0\n",
      "2         0.0     0.0   ...       0.0     0.0\n",
      "3         0.0     0.0   ...       0.0     0.0\n",
      "32        0.0     0.0   ...       0.0     0.0\n",
      "4         0.0     0.0   ...       0.0     0.0\n",
      "54        0.0     0.0   ...       0.0     0.0\n",
      "a         2.0     4.0   ...       2.0     7.0\n",
      "about     0.0     1.0   ...       0.0     0.0\n",
      "\n",
      "[10 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "tmt.index_wordcount.print_index(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "09.txt    1.0\n",
       "08.txt    1.0\n",
       "02.txt    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmt.index_wordcount.search_wordcount_index(cr.content_directory, \"slice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
