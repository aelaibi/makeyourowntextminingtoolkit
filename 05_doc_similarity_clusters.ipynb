{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook to illustrate document similarity clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# following only used for development, reloads the modules with any code changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# inline matplotlib charts\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import our text mining toolkit\n",
    "import text_mining_toolkit as tmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_directory =  data_sets/recipes/txt/\n",
      "text_filename_pattern =  ??.txt\n",
      "self.documents populated =  22\n"
     ]
    }
   ],
   "source": [
    "cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/recipes/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(directory_of_files=\"data_sets/mystery_corpus_01/txt/\", text_filename_pattern=\"??.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/iraq_inquiry/txt/\", text_filename_pattern=\"the-report*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/clinton_emails/txt/\", text_filename_pattern=\"C0*.txt\")\n",
    "#cr = tmt.corpus_reader.CorpusReader(content_directory=\"data_sets/shakespeare_macbeth/txt/\", text_filename_pattern=\"macbeth_act_0?_scene_0?.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  00.txt\n",
      "processing  01.txt\n",
      "processing  02.txt\n",
      "processing  03.txt\n",
      "processing  04.txt\n",
      "processing  05.txt\n",
      "processing  06.txt\n",
      "processing  07.txt\n",
      "processing  08.txt\n",
      "processing  09.txt\n",
      "processing  10.txt\n",
      "processing  11.txt\n",
      "processing  12.txt\n",
      "processing  13.txt\n",
      "processing  14.txt\n",
      "processing  15.txt\n",
      "processing  16.txt\n",
      "processing  17.txt\n",
      "processing  18.txt\n",
      "processing  19.txt\n",
      "processing  20.txt\n",
      "processing  21.txt\n"
     ]
    }
   ],
   "source": [
    "# first clear index\n",
    "tmt.index_search.delete_indices(cr.content_directory)\n",
    "\n",
    "# for all documents in corpus\n",
    "for document_name in cr.get_documents():\n",
    "    #print(\"processing \", document_name)\n",
    "\n",
    "    # get document text\n",
    "    document_text = cr.get_text_by_document(document_name)\n",
    "\n",
    "    # simplify whitespace (remove newlines)\n",
    "    b = tmt.text_processing.simplify_whitespace(document_text)\n",
    "\n",
    "    # only keep alphanumeric characters, removes punctuation\n",
    "    c = tmt.text_processing.keep_alphanumeric(b)\n",
    "\n",
    "    # make lowercase\n",
    "    d = tmt.text_processing.to_lowercase(c)\n",
    "\n",
    "    # split into words list\n",
    "    dl = tmt.text_processing.split_text_into_words(d)\n",
    "    \n",
    "    # build n-grams\n",
    "    #gl = tmt.word_processing.build_ngrams_from_words(dl,2)\n",
    "\n",
    "    # remove stop words\n",
    "    #el = tmt.word_processing.remove_stop_words(dl, \"./stopwords/minimal-stop.txt\")\n",
    "    \n",
    "    # update index\n",
    "    tmt.index_search.create_wordcount_index_for_document(cr.content_directory, document_name, dl)\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving corpus co-occurrence matrix ...  data_sets/recipes/txt/matrix.cooccurrence\n"
     ]
    }
   ],
   "source": [
    "# merge document indices into a corpus index\n",
    "tmt.index_search.merge_wordcount_indices_for_corpus(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooccurrence_matrix_file  data_sets/recipes/txt/matrix.cooccurrence\n",
      "                 add  adding    ...        whole      with\n",
      "add         0.000000     0.0    ...     0.000000  1.139566\n",
      "adding      0.000000     0.0    ...     0.000000  0.778801\n",
      "after       0.569783     0.0    ...     0.000000  1.509196\n",
      "are         0.367879     0.0    ...     0.367879  1.875325\n",
      "artichokes  0.000000     0.0    ...     0.000000  0.000000\n",
      "as          0.000000     0.0    ...     0.569783  1.675172\n",
      "asparagus   0.000000     0.0    ...     0.000000  1.348584\n",
      "boiled      0.778801     0.0    ...     0.000000  1.348584\n",
      "boiling     0.000000     0.0    ...     0.000000  0.367879\n",
      "bread       0.000000     0.0    ...     0.000000  2.816488\n",
      "\n",
      "[10 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "tmt.index_search.print_index(cr.content_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmt.index_search.search_wordcount_index(cr.content_directory, \"bread soaked in milk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
